{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_keras_vgg16.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/zacqoo/semantic_segmentation_vegetation_colab/blob/master/main_keras_vgg16.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "KywkAWYI2HPA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# restart Kernel\n",
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hecnIXKbnBG6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**1. Check to see if you are using GPU**"
      ]
    },
    {
      "metadata": {
        "id": "v2v13lWO0Td2",
        "colab_type": "code",
        "outputId": "be3516a8-0617-4e22-d5d6-6e6c1dbeca55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "HjXJoLXP0qTT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Mount your Google Drive and allow Google Colab environment to access the files on your drive.**"
      ]
    },
    {
      "metadata": {
        "id": "88J-pudW9e_Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N9cgLY-59h0w",
        "colab_type": "code",
        "outputId": "b9478e06-90b9-401e-8e71-c54fbb06b4e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fine_tuned_model.zip  Other Documents\t\t    shark_fin\n",
            "model_dir.zip\t      satellite_vegetation_schisto  shark_pulse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GmBDphga04ba",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3. Start the main code here, import Keras libraries**"
      ]
    },
    {
      "metadata": {
        "id": "oroJUJu800yG",
        "colab_type": "code",
        "outputId": "083790a3-9348-474e-9444-30cc05ed085c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# import keras libraries\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import TensorBoard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eAcRYPzx1Mgl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.engine.topology import Input\n",
        "from keras.engine.training import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
        "from keras.layers.core import Activation, SpatialDropout2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers import Input, merge\n",
        "from keras import backend as K\n",
        "from keras.backend.tensorflow_backend import _to_tensor\n",
        "from keras.losses import binary_crossentropy\n",
        "K.set_image_data_format(\"channels_last\")\n",
        "\n",
        "## metrics\n",
        "#from keras import backend as K\n",
        "SMOOTH_LOSS = 1e-12\n",
        "\n",
        "def jaccard_coef(y_true, y_pred):\n",
        "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
        "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
        "    jac = (intersection + SMOOTH_LOSS) / (sum_ - intersection + SMOOTH_LOSS)\n",
        "    return K.mean(jac)\n",
        "\n",
        "def jaccard_coef_int(y_true, y_pred):\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "\n",
        "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
        "    sum_ = K.sum(y_true + y_pred_pos, axis=[0, -1, -2])\n",
        "    jac = (intersection + SMOOTH_LOSS) / (sum_ - intersection + SMOOTH_LOSS)\n",
        "    return K.mean(jac)\n",
        "\n",
        "def jacard_coef_flat(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (intersection + SMOOTH_LOSS) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + SMOOTH_LOSS)\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "  \n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    dice_loss = 1 - dice_coef(y_true, y_pred)\n",
        "    return dice_loss\n",
        "\n",
        "def bootstrapped_crossentropy(y_true, y_pred, bootstrap_type='hard', alpha=0.95):\n",
        "    target_tensor = y_true\n",
        "    prediction_tensor = y_pred\n",
        "    _epsilon = _to_tensor(K.epsilon(), prediction_tensor.dtype.base_dtype)\n",
        "    prediction_tensor = K.tf.clip_by_value(prediction_tensor, _epsilon, 1 - _epsilon)\n",
        "    prediction_tensor = K.tf.log(prediction_tensor / (1 - prediction_tensor))\n",
        "\n",
        "    if bootstrap_type == 'soft':\n",
        "        bootstrap_target_tensor = alpha * target_tensor + (1.0 - alpha) * K.tf.sigmoid(prediction_tensor)\n",
        "    else:\n",
        "        bootstrap_target_tensor = alpha * target_tensor + (1.0 - alpha) * K.tf.cast(\n",
        "            K.tf.sigmoid(prediction_tensor) > 0.5, K.tf.float32)\n",
        "    return K.mean(K.tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "        labels=bootstrap_target_tensor, logits=prediction_tensor))\n",
        "\n",
        "def dice_coef_loss_bce(y_true, y_pred):\n",
        "    dice = 0.5\n",
        "    bce = 0.5\n",
        "    bootstrapping = 'hard'\n",
        "    alpha = 1.\n",
        "    return bootstrapped_crossentropy(y_true, y_pred, bootstrapping, alpha) * bce + dice_coef_loss(y_true, y_pred) * dice  \n",
        "\n",
        "def unet_vgg(PATCH_SZ, num_channels, num_classes):\n",
        "    input_shape_base = (None, None, num_channels)\n",
        "    img_input = Input(input_shape_base)\n",
        "    vgg16_base = VGG16(input_tensor=img_input, include_top=False, weights=None)\n",
        "    #for l in vgg16_base.layers:\n",
        "    #    l.trainable = True\n",
        "\n",
        "    conv1 = vgg16_base.get_layer(\"block1_conv2\").output\n",
        "    conv2 = vgg16_base.get_layer(\"block2_conv2\").output\n",
        "    conv3 = vgg16_base.get_layer(\"block3_conv3\").output\n",
        "    \n",
        "    pool3 = vgg16_base.get_layer(\"block3_pool\").output\n",
        "    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block4_conv1\")(pool3)\n",
        "    conv4 = Conv2D(384, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block4_conv2\")(conv4)\n",
        "   # pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(conv4)\n",
        "    pool4 = MaxPooling2D((2, 2), strides=None, name='block4_pool')(conv4)\n",
        "\n",
        "    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block5_conv1\")(pool4)\n",
        "    conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block5_conv2\")(conv5)\n",
        "   # pool5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(conv5)\n",
        "    pool5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(conv5)\n",
        "\n",
        "    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block6_conv1\")(pool5)\n",
        "    conv6 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block6_conv2\")(conv6)\n",
        "    #pool6 = MaxPooling2D((2, 2), strides=(2, 2), name='block6_pool')(conv6)\n",
        "    pool6 = MaxPooling2D((2, 2), strides=(2,2), name='block6_pool')(conv6)\n",
        "\n",
        "    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block7_conv1\")(pool6)\n",
        "    conv7 = Conv2D(512, (3, 3), activation=\"relu\", padding='same', kernel_initializer=\"he_normal\", name=\"block7_conv2\")(conv7)\n",
        "\n",
        "    #up8 = concatenate([Conv2DTranspose(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='valid')(conv7), conv6], axis=3)\n",
        "    up8 = merge([Conv2DTranspose(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv7), conv6], mode='concat', concat_axis=3)\n",
        "    conv8 = Conv2D(384, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv8), conv5], axis=3)\n",
        "    conv9 = Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up9)\n",
        "\n",
        "    up10 = concatenate([Conv2DTranspose(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv9), conv4], axis=3)\n",
        "    conv10 = Conv2D(192, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up10)\n",
        "\n",
        "    up11 = concatenate([Conv2DTranspose(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv10), conv3], axis=3)\n",
        "    conv11 = Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up11)\n",
        "\n",
        "    up12 = concatenate([Conv2DTranspose(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv11), conv2], axis=3)\n",
        "    conv12 = Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up12)\n",
        "\n",
        "    up13 = concatenate([Conv2DTranspose(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", strides=(2, 2), padding='same')(conv12), conv1], axis=3)\n",
        "    conv13 = Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding='same')(up13)\n",
        "\n",
        "    # #Batch normalization\n",
        "    #conv13 = BatchNormalization(mode=0, axis=1)(conv13)\n",
        "\n",
        "    conv13 = Conv2D(num_classes, (1, 1), activation='sigmoid')(conv13)\n",
        "    #conv13 = Conv2D(1, (1, 1))(conv13)\n",
        "    #conv13 = Activation(\"sigmoid\")(conv13)\n",
        "    model = Model(img_input, conv13)\n",
        "\n",
        "    # Recalculate weights on first layer\n",
        "    conv1_weights = np.zeros((3, 3, num_channels, 64), dtype=\"float32\")\n",
        "    vgg = VGG16(include_top=False, input_shape=(PATCH_SZ, PATCH_SZ, 3), weights = 'imagenet')\n",
        "    #conv1_weights[:, :, :3, :] = vgg.get_layer(\"block1_conv1\").get_weights()[0][:, :, :, :]\n",
        "    conv1_weights[:, :, 0, :] = vgg.get_layer(\"block1_conv1\").get_weights()[0][:, :, 0, :] #R\n",
        "    conv1_weights[:, :, 1, :] = vgg.get_layer(\"block1_conv1\").get_weights()[0][:, :, 1, :] #G\n",
        "    conv1_weights[:, :, 2, :] = vgg.get_layer(\"block1_conv1\").get_weights()[0][:, :, 2, :] #B\n",
        "    \n",
        "    bias = vgg.get_layer(\"block1_conv1\").get_weights()[1]\n",
        "    model.get_layer('block1_conv1').set_weights((conv1_weights, bias))\n",
        "    model.compile(optimizer=Adam(lr = 2e-5), loss = dice_coef_loss_bce,#loss='binary_crossentropy',  \n",
        "                  metrics=[#jaccard_coef,  \n",
        "                           #jacard_coef_flat,\n",
        "                           #jaccard_coef_int,  \n",
        "                           dice_coef, 'accuracy'])\n",
        "    # model.summary()\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gV9oFdZ21Pmx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## patches\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def get_rand_patch(img, mask, sz):\n",
        "    \"\"\"\n",
        "    :param img: ndarray with shape (x_sz, y_sz, num_channels)\n",
        "    :param mask: binary ndarray with shape (x_sz, y_sz, num_classes)\n",
        "    :param sz: size of random patch\n",
        "    :return: patch with shape (sz, sz, num_channels)\n",
        "    \"\"\"\n",
        "    assert len(img.shape) == 3 and img.shape[0] > sz and img.shape[1] > sz and img.shape[0:2] == mask.shape[0:2]\n",
        "    xc = random.randint(0, img.shape[0] - sz)\n",
        "    yc = random.randint(0, img.shape[1] - sz)\n",
        "    patch_img = img[xc:(xc + sz), yc:(yc + sz)]\n",
        "    patch_mask = mask[xc:(xc + sz), yc:(yc + sz)]\n",
        "\n",
        "    # Apply some random transformations\n",
        "    random_transformation = np.random.randint(1,8)\n",
        "    if random_transformation == 1:  # reverse first dimension\n",
        "        patch_img = patch_img[::-1,:,:]\n",
        "        patch_mask = patch_mask[::-1,:,:]\n",
        "    elif random_transformation == 2:    # reverse second dimension\n",
        "        patch_img = patch_img[:,::-1,:]\n",
        "        patch_mask = patch_mask[:,::-1,:]\n",
        "    elif random_transformation == 3:    # transpose(interchange) first and second dimensions\n",
        "        patch_img = patch_img.transpose([1,0,2])\n",
        "        patch_mask = patch_mask.transpose([1,0,2])\n",
        "    elif random_transformation == 4:\n",
        "        patch_img = np.rot90(patch_img, 1)\n",
        "        patch_mask = np.rot90(patch_mask, 1)\n",
        "    elif random_transformation == 5:\n",
        "        patch_img = np.rot90(patch_img, 2)\n",
        "        patch_mask = np.rot90(patch_mask, 2)\n",
        "    elif random_transformation == 6:\n",
        "        patch_img = np.rot90(patch_img, 3)\n",
        "        patch_mask = np.rot90(patch_mask, 3)\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    return patch_img, patch_mask\n",
        "\n",
        "\n",
        "def get_patches(x_dict, y_dict, n_patches, sz):\n",
        "    x = list()\n",
        "    y = list()\n",
        "    total_patches = 0\n",
        "    while total_patches < n_patches:\n",
        "        img_id = random.sample(x_dict.keys(), 1)[0]\n",
        "        img = x_dict[img_id]\n",
        "        mask = y_dict[img_id]\n",
        "        img_patch, mask_patch = get_rand_patch(img, mask, sz)\n",
        "        x.append(img_patch)\n",
        "        y.append(mask_patch)\n",
        "        total_patches += 1\n",
        "    print('Generated {} patches'.format(total_patches))\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "\n",
        "def get_TEST_patches(x_dict, n_patches, sz):\n",
        "    x = list()\n",
        "    keys = list(x_dict.keys())\n",
        "    for i in range(n_patches):\n",
        "        img = x_dict[keys[i]]\n",
        "        szx = int(img.shape[0]/sz)\n",
        "        szy = int(img.shape[1]/sz)\n",
        "        for j in range(szx):\n",
        "            for k in range(szy):\n",
        "                patch_img = img[j*sz:(j+1)*sz, k*sz:(k+1)*sz, :]\n",
        "                x.append(patch_img)\n",
        "    print('Generated {} patches'.format(n_patches*szx*szy))\n",
        "    return np.array(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oMQB3RMN1u-X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import skimage.io as io\n",
        "import os\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ia9qsBov10CD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install tifffile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zzdyn31I13jX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tifffile as tiff"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EPlgPNJZ15K_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# config.\n",
        "PATCH_SZ = 256   # should divide by 16\n",
        "BATCH_SIZE = 32\n",
        "TRAIN_SZ = 1000  # train size\n",
        "VAL_SZ = 400    # validation size\n",
        "N_EPOCHS = 1 #150\n",
        "N_STEPS = 500\n",
        "num_channels = 3\n",
        "num_classes = 2\n",
        "IMG_SZ = 512\n",
        "\n",
        "weights_folder = 'drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/weights/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kC9jwaUs3BbG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_DICT_TRAIN = dict()\n",
        "Y_DICT_TRAIN = dict()\n",
        "X_DICT_VALIDATION = dict()\n",
        "Y_DICT_VALIDATION = dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RRuVhiJP3CB0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_image = 'drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/data/training_set/images/'\n",
        "path_mask = 'drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/data/training_set/label/'\n",
        "#image_selection = [0,1,2,4,5,8,9,10,13,18,22,23,25,26,29,30,32,34,35,36,37,43,44,46,47]\n",
        "\n",
        "for img_id in image_selection:\n",
        "    img_m = io.imread(os.path.join(path_image + '{}.png'.format(img_id)), img_num=0)\n",
        "    mask_c = io.imread(os.path.join(path_mask + 'Cera_masks/{}.png'.format(img_id)))\n",
        "    mask_e = io.imread(os.path.join(path_mask + 'Emergent_masks/{}.png'.format(img_id)))\n",
        "    \n",
        "    for i in range(0,5):\n",
        "        for j in range(0,7):\n",
        "            mask = np.zeros((IMG_SZ,IMG_SZ,num_classes))\n",
        "            mask[:,:,0] = mask_c[i*IMG_SZ:(i+1)*IMG_SZ,j*IMG_SZ:(j+1)*IMG_SZ]\n",
        "            mask[:,:,1] = mask_e[i*IMG_SZ:(i+1)*IMG_SZ,j*IMG_SZ:(j+1)*IMG_SZ]\n",
        "            mask = mask/255\n",
        "            \n",
        "            img_p = np.zeros((IMG_SZ,IMG_SZ,3))\n",
        "            img_p = img_m[i*IMG_SZ:(i+1)*IMG_SZ,j*IMG_SZ:(j+1)*IMG_SZ,:]\n",
        "            \n",
        "            # 35 parsed images go to training; 13 go to validation \n",
        "            X_DICT_TRAIN[img_id,i,j] = img_p\n",
        "            Y_DICT_TRAIN[img_id,i,j] = mask\n",
        "            #X_DICT_VALIDATION[img_id,i,j] = img_p\n",
        "            #Y_DICT_VALIDATION[img_id,i,j] = mask\n",
        "    \n",
        "    for i in range(5,6):\n",
        "        for j in range(0,7):\n",
        "            mask = np.zeros((IMG_SZ,IMG_SZ,num_classes))\n",
        "            mask[:,:,0] = mask_c[i*IMG_SZ-72:3000,j*IMG_SZ:(j+1)*IMG_SZ]\n",
        "            mask[:,:,1] = mask_e[i*IMG_SZ-72:3000,j*IMG_SZ:(j+1)*IMG_SZ]\n",
        "            mask = mask/255\n",
        "            \n",
        "            img_p = np.zeros((IMG_SZ,IMG_SZ,3))\n",
        "            img_p = img_m[i*IMG_SZ-72:3000,j*IMG_SZ:(j+1)*IMG_SZ,:]\n",
        "            \n",
        "            #X_DICT_TRAIN[img_id,i,j] = img_p\n",
        "            #Y_DICT_TRAIN[img_id,i,j] = mask\n",
        "            X_DICT_VALIDATION[img_id,i,j] = img_p\n",
        "            Y_DICT_VALIDATION[img_id,i,j] = mask\n",
        "    \n",
        "    for i in range(0,5):\n",
        "        for j in range(7,8):\n",
        "            mask = np.zeros((IMG_SZ,IMG_SZ,num_classes))\n",
        "            mask[:,:,0] = mask_c[i*IMG_SZ:(i+1)*IMG_SZ,j*IMG_SZ-96:4000]\n",
        "            mask[:,:,1] = mask_e[i*IMG_SZ:(i+1)*IMG_SZ,j*IMG_SZ-96:4000]\n",
        "            mask = mask/255\n",
        "            \n",
        "            img_p = np.zeros((IMG_SZ,IMG_SZ,3))\n",
        "            img_p = img_m[i*IMG_SZ:(i+1)*IMG_SZ,j*IMG_SZ-96:4000,:]\n",
        "            \n",
        "            #X_DICT_TRAIN[img_id,i,j] = img_p\n",
        "            #Y_DICT_TRAIN[img_id,i,j] = mask\n",
        "            X_DICT_VALIDATION[img_id,i,j] = img_p\n",
        "            Y_DICT_VALIDATION[img_id,i,j] = mask\n",
        "    \n",
        "    for i in range(5,6):\n",
        "        for j in range(7,8):\n",
        "            mask = np.zeros((IMG_SZ,IMG_SZ,num_classes))\n",
        "            mask[:,:,0] = mask_c[i*IMG_SZ-72:3000,j*IMG_SZ-96:4000]\n",
        "            mask[:,:,1] = mask_e[i*IMG_SZ-72:3000,j*IMG_SZ-96:4000]\n",
        "            mask = mask/255\n",
        "            \n",
        "            img_p = np.zeros((IMG_SZ,IMG_SZ,3))\n",
        "            img_p = img_m[i*IMG_SZ-72:3000,j*IMG_SZ-96:4000,:]\n",
        "            \n",
        "            #X_DICT_TRAIN[img_id,i,j] = img_p\n",
        "            #Y_DICT_TRAIN[img_id,i,j] = mask\n",
        "            X_DICT_VALIDATION[img_id,i,j] = img_p\n",
        "            Y_DICT_VALIDATION[img_id,i,j] = mask\n",
        "            \n",
        "    print('read ', img_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jAeCEWS-31EP",
        "colab_type": "code",
        "outputId": "82899653-5a04-4fbc-e5e3-1daca26511ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train = get_patches(X_DICT_TRAIN, Y_DICT_TRAIN, n_patches=TRAIN_SZ, sz=PATCH_SZ)\n",
        "x_val, y_val = get_patches(X_DICT_VALIDATION, Y_DICT_VALIDATION, n_patches=VAL_SZ, sz=PATCH_SZ)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated 1000 patches\n",
            "Generated 400 patches\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EdCSsJn534Gd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**6. Start training**"
      ]
    },
    {
      "metadata": {
        "id": "4QKE_Ny-33cu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train method 1\n",
        "model = unet_vgg(PATCH_SZ, num_channels, num_classes)\n",
        "model_checkpoint = ModelCheckpoint('unet_c_e_vgg16.hdf5', monitor='val_loss', save_best_only=True)\n",
        "csv_logger = CSVLogger('drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/log_unet_c_e_vgg16.csv', append=True, separator=';')\n",
        "tensorboard = TensorBoard(log_dir='drive/satellite_vegetation_schisto/code/unet_v3_drone/tensorboard_unet/', write_graph=True, write_images=True)\n",
        "\n",
        "print(\"start train net\")\n",
        "start_time = time.time()\n",
        "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n",
        "          verbose=1, shuffle=True,\n",
        "          callbacks=[model_checkpoint, csv_logger, tensorboard],\n",
        "          validation_data=(x_val, y_val), class_weight=[1.0, 0.65])\n",
        "print(\"---  Training for %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0DyvlrnS38hM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train method 2\n",
        "model = unet_vgg(PATCH_SZ, num_channels, num_classes)\n",
        "model_checkpoint = ModelCheckpoint('unet_c_e_vgg16.hdf5', monitor='val_loss', save_best_only=True)\n",
        "csv_logger = CSVLogger('drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/log_unet_c_e_vgg16.csv', append=True, separator=';')\n",
        "tensorboard = TensorBoard(log_dir='drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/tensorboard_unet/', write_graph=True, write_images=True)\n",
        "\n",
        "print(\"start train net\")\n",
        "start_time = time.time()\n",
        "for i in range(N_STEPS):\n",
        "    print(\"Step i\", i)\n",
        "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n",
        "          verbose=1, shuffle=True,\n",
        "          callbacks=[model_checkpoint, csv_logger, tensorboard],\n",
        "          validation_data=(x_val, y_val))#, class_weight=[0.8, 1.0])\n",
        "    #Get ready for next step\n",
        "    del x_train\n",
        "    del y_train\n",
        "    x_train, y_train = get_patches(X_DICT_TRAIN, Y_DICT_TRAIN, n_patches=TRAIN_SZ, sz=PATCH_SZ)\n",
        "print(\"---  Training for %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zSxdi2tPbIKx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# save weights to drive\n",
        "model.save_weights('drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/unet_c_e_vgg16.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y34aPe1FbAn_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## load weights if continuing training with existing weights\n",
        "\n",
        "# train method 1\n",
        "model = unet_vgg(PATCH_SZ, num_channels, num_classes)\n",
        "model.load_weights('drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/unet_c_e_vgg16.hdf5')\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('unet_c_e_vgg16.hdf5', monitor='cal_loss', save_best_only=True)\n",
        "csv_logger = CSVLogger('drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/log_unet_c_e_vgg16.csv', append=True, separator=';')\n",
        "tensorboard = TensorBoard(log_dir='drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/tensorboard_unet/', write_graph=True, write_images=True)\n",
        "\n",
        "print(\"start train net\")\n",
        "start_time = time.time()\n",
        "model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n",
        "          verbose=1, shuffle=True,\n",
        "          callbacks=[model_checkpoint, csv_logger, tensorboard],\n",
        "          validation_data=(x_val, y_val))#, class_weight=[.8,1.0,.1,.3])\n",
        "print(\"---  Training for %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I4IdXzvibBoi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train method 2\n",
        "model = unet_vgg(PATCH_SZ, num_channels, num_classes)\n",
        "model.load_weights('drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/unet_c_e_vgg16.hdf5')\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('unet_c_e_vgg16_continue.hdf5', monitor='val_loss', save_best_only=True)\n",
        "csv_logger = CSVLogger('drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/log_unet_c_e_vgg16_continue.csv', append=True, separator=';')\n",
        "tensorboard = TensorBoard(log_dir='drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/tensorboard_unet/', write_graph=True, write_images=True)\n",
        "\n",
        "print(\"start train net\")\n",
        "start_time = time.time()\n",
        "for i in range(N_STEPS):\n",
        "    print(\"Step \", i)\n",
        "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS,\n",
        "          verbose=1, shuffle=True,\n",
        "          callbacks=[model_checkpoint, csv_logger, tensorboard],\n",
        "          validation_data=(x_val, y_val), class_weight=[0.9, 1.0])\n",
        "    #Get ready for next step\n",
        "    del x_train\n",
        "    del y_train\n",
        "    x_train, y_train = get_patches(X_DICT_TRAIN, Y_DICT_TRAIN, n_patches=TRAIN_SZ, sz=PATCH_SZ)\n",
        "print(\"---  Training for %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jbMkHbyxbGK3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# save weights to drive\n",
        "model.save_weights('drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/unet_c_e_vgg16_continue.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pPvFZVzlI1w6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**7. Generate prediction and output mask images**"
      ]
    },
    {
      "metadata": {
        "id": "rrUrhdH3b23G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = unet_vgg(PATCH_SZ, num_channels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AwpNp8f-3-pe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## load weights\n",
        "model.load_weights('drive/My Drive/satellite_vegetation_schisto/code/unet_v3_drone/unet_c_e_vgg16.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Pzsy3dJI7E-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## make predictions\n",
        "TEST_SZ = 4\n",
        "path_test = 'drive//My Drive/satellite_vegetation_schisto/code/unet_v3_drone/data/test_set/images/'\n",
        "\n",
        "X_DICT_TEST = dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TRugiHeuJTIO",
        "colab_type": "code",
        "outputId": "4eab3b20-b8ec-45ca-83ae-0d193ceb13fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "for img_id in range(0, TEST_SZ):\n",
        "    img_m = io.imread(os.path.join(path_test + '{}.png'.format(img_id)), img_num=0)\n",
        "    #X_DICT_TEST[img_id] = img_m[:, :, :]\n",
        "    \n",
        "    for i in range(0,5):\n",
        "        for j in range(0,7):            \n",
        "            img_p = np.zeros((IMG_SZ,IMG_SZ,3))\n",
        "            img_p = img_m[i*IMG_SZ:(i+1)*IMG_SZ,j*IMG_SZ:(j+1)*IMG_SZ,:] \n",
        "            X_DICT_TEST[img_id,i,j] = img_p\n",
        "    \n",
        "    for i in range(5,6):\n",
        "        for j in range(0,7):\n",
        "            img_p = np.zeros((IMG_SZ,IMG_SZ,3))\n",
        "            img_p = img_m[i*IMG_SZ-72:3000,j*IMG_SZ:(j+1)*IMG_SZ,:]\n",
        "            X_DICT_TEST[img_id,i,j] = img_p\n",
        "    \n",
        "    for i in range(0,5):\n",
        "        for j in range(7,8):\n",
        "            img_p = np.zeros((IMG_SZ,IMG_SZ,3))\n",
        "            img_p = img_m[i*IMG_SZ:(i+1)*IMG_SZ,j*IMG_SZ-96:4000,:]\n",
        "            X_DICT_TEST[img_id,i,j] = img_p\n",
        "    \n",
        "    for i in range(5,6):\n",
        "        for j in range(7,8):\n",
        "            img_p = np.zeros((IMG_SZ,IMG_SZ,3))\n",
        "            img_p = img_m[i*IMG_SZ-72:3000,j*IMG_SZ-96:4000,:]\n",
        "            X_DICT_TEST[img_id,i,j] = img_p\n",
        "    \n",
        "    print('read_', img_id)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "read_ 0\n",
            "read_ 1\n",
            "read_ 2\n",
            "read_ 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8NEl7uZDRZti",
        "colab_type": "code",
        "outputId": "57fcc52e-cee5-4a22-89cb-53f97d9311d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(X_DICT_TEST)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "192"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "tsQqyBlRJU_J",
        "colab_type": "code",
        "outputId": "2d0791ea-1064-4484-9982-e6b0a5965222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "x_test = get_TEST_patches(X_DICT_TEST, n_patches=TEST_SZ, sz=PATCH_SZ)\n",
        "results = model.predict(x_test,verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated 16 patches\n",
            "16/16 [==============================] - 1s 44ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hc2HNd9HLdGS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## save predictions\n",
        "Path_pred = 'drive//My Drive/satellite_vegetation_schisto/code/unet_v3_drone/data/test_set/prediction/'\n",
        "\n",
        "def Visualize(num_classes, PATCH_SZ, img):\n",
        "    for i in range(PATCH_SZ):\n",
        "        for j in range(PATCH_SZ):\n",
        "            for k in range(num_classes):\n",
        "                #a = [im_0[i,j], im_1[i,j], im_2[i,j], im_3[i,j]]\n",
        "                a = [img[:,:,0][i,j], img[:,:,1][i,j]]#, img[:,:,2][i,j], img[:,:,3][i,j]]\n",
        "                ind = a.index(max(a))\n",
        "                if ind == k: #and max(a) > 0.75:\n",
        "                    img[i,j,k] = img[:,:,k][i,j]\n",
        "                else:\n",
        "                    img[i,j,k] = 0\n",
        "            \n",
        "    colors = {\n",
        "        0: [255, 0, 0],  # Ceratophyllum- red\n",
        "        1: [0, 204, 0],  # Emergent- bright green\n",
        "        #0: [255, 255, 0],    # Land- yellow\n",
        "        #1: [0, 255, 255],  # Water- light blue\n",
        "    }\n",
        "    \n",
        "    img_out = np.zeros(shape=(PATCH_SZ, PATCH_SZ, 3), dtype=np.uint8)\n",
        "    img_out[:,:,0] = img[:,:,0]*colors[0][0] + img[:,:,1]*colors[1][0] #+ img[:,:,2]*colors[2][0] + img[:,:,3]*colors[3][0]\n",
        "    img_out[:,:,1] = img[:,:,0]*colors[0][1] + img[:,:,1]*colors[1][1] #+ img[:,:,2]*colors[2][1] + img[:,:,3]*colors[3][1]\n",
        "    img_out[:,:,2] = img[:,:,0]*colors[0][2] + img[:,:,1]*colors[1][2] #+ img[:,:,2]*colors[2][2] + img[:,:,3]*colors[3][2]\n",
        "    return img_out/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D2ln5xMKMC0d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# combine prediction patches to outputs\n",
        "complete = np.zeros((512,512,3))\n",
        "for i,item in enumerate(results):\n",
        "    img = Visualize(num_classes,PATCH_SZ,item)\n",
        "    if i%4 == 0:\n",
        "        complete[0:PATCH_SZ, 0:PATCH_SZ , :] = img\n",
        "    elif i%4 == 1:\n",
        "        complete[0:PATCH_SZ,PATCH_SZ:2*PATCH_SZ,:] = img\n",
        "    elif i%4 == 2:\n",
        "        complete[PATCH_SZ:2*PATCH_SZ, 0:PATCH_SZ,:] = img\n",
        "    else:\n",
        "        complete[PATCH_SZ:2*PATCH_SZ,PATCH_SZ:2*PATCH_SZ,:] = img\n",
        "    io.imsave(Path_pred + \"%d_predict.png\"%(i/4), complete)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OqJzFTthMF_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# method 2\n",
        "Path_pred = 'drive/satellite_vegetation_schisto/code/unet_v5_pre_trained/data/test_set/prediction/'\n",
        "\n",
        "land = [255,255,0] #yellow \n",
        "water = [0,255,255] #light blue\n",
        "emergent = [0,204,0] #bright green\n",
        "Ceratophyllum = [255,0,0]#red\n",
        "COLOR_DICT = np.array([Ceratophyllum, emergent, land, water])\n",
        "\n",
        "def labelVisualize(num_class,color_dict,img):\n",
        "    img_out = np.zeros((256,256,3))\n",
        "    for i in range(PATCH_SZ):\n",
        "        for j in range(PATCH_SZ):\n",
        "            for k in range(num_class):\n",
        "                #a = [im_0[i,j], im_1[i,j], im_2[i,j], im_3[i,j]]\n",
        "                a = [img[i,j,0], img[i,j,1]]#, img[i,j,2], img[i,j,3]]\n",
        "                #print (a)\n",
        "                ind = a.index(max(a))\n",
        "                if ind == k:\n",
        "                    img_out[i,j,:] = COLOR_DICT[k]\n",
        "    return img_out/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ej6RtKzzMH0v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# combine prediction patches to outputs\n",
        "complete = np.zeros((512,512,3))\n",
        "for i,item in enumerate(results):\n",
        "    img = labelVisualize(num_classes,COLOR_DICT,item) #if flag_multi_class else item[:,:,0]\n",
        "    #print (img)\n",
        "    \n",
        "    if i%4 == 0:\n",
        "        complete[0:PATCH_SZ, 0:PATCH_SZ ] = img\n",
        "    elif i%4 == 1:\n",
        "        complete[0:PATCH_SZ,PATCH_SZ:2*PATCH_SZ] = img\n",
        "    elif i%4 == 2:\n",
        "        complete[PATCH_SZ:2*PATCH_SZ, 0:PATCH_SZ] = img\n",
        "    else:\n",
        "        complete[PATCH_SZ:2*PATCH_SZ,PATCH_SZ:2*PATCH_SZ] = img\n",
        "        io.imsave(Path_pred + \"%d_predict.png\"%(i/4),complete)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}